/* tslint:disable */
/* eslint-disable */

/* auto-generated by NAPI-RS */

export interface ClipOptions {
  visionModelPath: string
  textModelPath: string
  tokenizerPath: string
  contextLength: number
  visionSize: number
}
export interface FacePrediction {
  score: number
  bbox: BoundBox
  landmarks: Array<Landmark>
}
export interface Face {
  prediction: FacePrediction
  embedding: Array<number>
}
export interface FaceRecognitionOptions {
  detectionModelPath: string
  embeddingModelPath: string
}
export interface BoundBox {
  x1: number
  y1: number
  x2: number
  y2: number
}
export interface Landmark {
  x: number
  y: number
}
export class Clip {
  constructor(options: ClipOptions)
  unloadTextualSession(): void
  unloadVisualSession(): void
  batchEncodeText(text: Array<string>): Promise<Array<Array<number>>>
  batchEncodeImages(imagePaths: Array<string>): Promise<Array<Array<number>>>
}
export class FaceRecognition {
  constructor(options: FaceRecognitionOptions)
  /** Predict faces in an image, returning the faces and embeddings. */
  predict(imagePath: string): Promise<Array<Face>>
}
